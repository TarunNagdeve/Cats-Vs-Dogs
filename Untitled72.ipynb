{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR8wtuFQt0BVMlqhQ771ZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarunNagdeve/Cats-Vs-Dogs/blob/master/Untitled72.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6qEM_Dl6n0m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers\n",
        "from keras.applications import EfficientNetB0\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Perform text detection\n",
        "text_detector = cv2.text.TextDetectorCNN_create(\"path/to/opencv_text_detection.pb\")\n",
        "_, text_regions = text_detector.detect(blur)\n",
        "\n",
        "# Create a mask for the text regions\n",
        "text_mask = np.zeros_like(gray)\n",
        "for region in text_regions:\n",
        "    x, y, w, h = region[0]\n",
        "    cv2.rectangle(text_mask, (x, y), (x + w, y + h), (255), cv2.FILLED)\n",
        "\n",
        "# Find contours excluding text regions\n",
        "contours, _ = cv2.findContours(cv2.bitwise_not(text_mask), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Draw contours on the original image\n",
        "contour_image = cv2.drawContours(image.copy(), contours, contourIdx=-1, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Text and Contour Detection', np.hstack((image, contour_image)))\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "qUjgrC6KVLqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Perform text detection\n",
        "text_detection = cv2.text.detectText(blur, cv2.text.OCR_KNN_MODEL)\n",
        "\n",
        "# Get the detected text regions\n",
        "text_regions = text_detection[0]\n",
        "\n",
        "# Create a mask for the text regions\n",
        "text_mask = cv2.drawContours(\n",
        "    np.zeros_like(gray), text_regions, contourIdx=-1, color=255, thickness=cv2.FILLED\n",
        ")\n",
        "\n",
        "# Find contours excluding text regions\n",
        "contours, _ = cv2.findContours(cv2.bitwise_not(text_mask), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Draw contours on the original image\n",
        "contour_image = cv2.drawContours(image.copy(), contours, contourIdx=-1, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Text and Contour Detection', np.hstack((image, contour_image)))\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "06PNtj1HUN9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "def process_image(image):\n",
        "    # Convert the image bytes to a numpy array\n",
        "    nparr = np.frombuffer(image.read(), np.uint8)\n",
        "\n",
        "    # Decode the numpy array to an image\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image (e.g., resize, normalize, etc.)\n",
        "    # ...\n",
        "\n",
        "    return img\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1 = request.files['image1']\n",
        "    image2 = request.files['image2']\n",
        "\n",
        "    # Process the images\n",
        "    processed_image1 = process_image(image1)\n",
        "    processed_image2 = process_image(image2)\n",
        "\n",
        "    # Perform prediction using the loaded model and the processed images\n",
        "    prediction = model.predict([processed_image1, processed_image2])\n",
        "\n",
        "    # Create a dataframe of the predicted values\n",
        "    df = pd.DataFrame(prediction, columns=['Predicted Values'])\n",
        "\n",
        "    # Return the dataframe as JSON response\n",
        "    return df.to_json()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Prepare the image files as bytes\n",
        "    image_bytes1 = uploaded_image1.read()\n",
        "    image_bytes2 = uploaded_image2.read()\n",
        "\n",
        "    # Send the image bytes to the API\n",
        "    files = {'image1': ('image1.jpg', io.BytesIO(image_bytes1), 'image/jpeg'),\n",
        "             'image2': ('image2.jpg', io.BytesIO(image_bytes2), 'image/jpeg')}\n",
        "    response = requests.post(API_URL, files=files)\n",
        "\n",
        "    # Convert the JSON response to a dataframe\n",
        "    df = pd.read_json(response.content)\n",
        "\n",
        "    # Display the dataframe\n",
        "    st.write('Predicted Values:')\n",
        "    st.dataframe(df)\n"
      ],
      "metadata": {
        "id": "j1PaNi1IPaLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "def process_image(image_data):\n",
        "    # Decode the base64 encoded image data\n",
        "    nparr = np.frombuffer(base64.b64decode(image_data), np.uint8)\n",
        "\n",
        "    # Decode the numpy array to an image\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image (e.g., resize, normalize, etc.)\n",
        "    # ...\n",
        "\n",
        "    return img\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1_data = request.form['image1']\n",
        "    image2_data = request.form['image2']\n",
        "\n",
        "    # Process the images\n",
        "    processed_image1 = process_image(image1_data)\n",
        "    processed_image2 = process_image(image2_data)\n",
        "\n",
        "    # Perform prediction using the loaded model and the processed images\n",
        "    prediction = model.predict([processed_image1, processed_image2])\n",
        "\n",
        "    # Create a dataframe of the predicted values\n",
        "    df = pd.DataFrame(prediction, columns=['Predicted Values'])\n",
        "\n",
        "    # Return the dataframe as JSON response\n",
        "    return df.to_json()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "import pandas as pd\n",
        "import base64\n",
        "import io\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Save the uploaded images\n",
        "    image_path1 = 'uploaded_image1.jpg'\n",
        "    image_path2 = 'uploaded_image2.jpg'\n",
        "    with open(image_path1, 'wb') as f1, open(image_path2, 'wb') as f2:\n",
        "        f1.write(uploaded_image1.getvalue())\n",
        "        f2.write(uploaded_image2.getvalue())\n",
        "\n",
        "    # Read the saved images as bytes\n",
        "    with open(image_path1, 'rb') as f1, open(image_path2, 'rb') as f2:\n",
        "        image_bytes1 = f1.read()\n",
        "        image_bytes2 = f2.read()\n",
        "\n",
        "    # Convert the image bytes to base64 encoded strings\n",
        "    image_data1 = base64.b64encode(image_bytes1).decode('utf-8')\n",
        "    image_data2 = base64.b64encode(image_bytes2).decode('utf-8')\n",
        "\n",
        "    # Send the base64 encoded image data to the API\n",
        "    data = {'image1': image_data1, 'image2': image_data2}\n",
        "    response = requests.post(API_URL, data=data)\n",
        "\n",
        "    # Convert the JSON response to a dataframe\n",
        "    df = pd.read_json(response.content)\n",
        "\n",
        "    # Display the dataframe\n",
        "    st.write('Predicted Values:')\n",
        "    st.dataframe(df)\n"
      ],
      "metadata": {
        "id": "HppPm8Zy1nGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "def process_image(image_data):\n",
        "    # Decode the base64 encoded image data\n",
        "    nparr = np.frombuffer(base64.b64decode(image_data), np.uint8)\n",
        "\n",
        "    # Decode the numpy array to an image\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image (e.g., resize, normalize, etc.)\n",
        "    # ...\n",
        "\n",
        "    return img\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1_data = request.form['image1']\n",
        "    image2_data = request.form['image2']\n",
        "\n",
        "    # Process the images\n",
        "    processed_image1 = process_image(image1_data)\n",
        "    processed_image2 = process_image(image2_data)\n",
        "\n",
        "    # Perform prediction using the loaded model and the processed images\n",
        "    prediction = model.predict([processed_image1, processed_image2])\n",
        "\n",
        "    # Create a dataframe of the predicted values\n",
        "    df = pd.DataFrame(prediction, columns=['Predicted Values'])\n",
        "\n",
        "    # Return the dataframe as JSON response\n",
        "    return df.to_json()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "import pandas as pd\n",
        "import base64\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Read the image files as bytes\n",
        "    image_bytes1 = uploaded_image1.read()\n",
        "    image_bytes2 = uploaded_image2.read()\n",
        "\n",
        "    # Convert the image bytes to base64 encoded strings\n",
        "    image_data1 = base64.b64encode(image_bytes1).decode('utf-8')\n",
        "    image_data2 = base64.b64encode(image_bytes2).decode('utf-8')\n",
        "\n",
        "    # Send the base64 encoded image data to the API\n",
        "    data = {'image1': image_data1, 'image2': image_data2}\n",
        "    response = requests.post(API_URL, data=data)\n",
        "\n",
        "    # Convert the JSON response to a dataframe\n",
        "    df = pd.read_json(response.content)\n",
        "\n",
        "    # Display the dataframe\n",
        "    st.write('Predicted Values:')\n",
        "    st.dataframe(df)\n"
      ],
      "metadata": {
        "id": "XYIKqYUvAeca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gm6GmPi61n4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1 = request.files['image1']\n",
        "    image2 = request.files['image2']\n",
        "\n",
        "    # Save the uploaded images\n",
        "    image1_path = 'uploaded_image1.jpg'\n",
        "    image2_path = 'uploaded_image2.jpg'\n",
        "    image1.save(image1_path)\n",
        "    image2.save(image2_path)\n",
        "\n",
        "    # Perform prediction using the loaded model and the image paths\n",
        "    prediction = model.predict([image1_path, image2_path])\n",
        "\n",
        "    # Prepare the response\n",
        "    response = {\n",
        "        'prediction': prediction.tolist()\n",
        "    }\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Send the uploaded images to the API\n",
        "    files = {'image1': uploaded_image1, 'image2': uploaded_image2}\n",
        "    response = requests.post(API_URL, files=files)\n",
        "\n",
        "    # Extract the prediction from the response\n",
        "    prediction = response.json()['prediction']\n",
        "\n",
        "    # Display the prediction\n",
        "    st.write('Prediction:', prediction)\n"
      ],
      "metadata": {
        "id": "WkNkDTFf8U4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MRW-Code/cmac_particle_flow.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irftjGuQ6odc",
        "outputId": "097102f2-7e58-42e5-85d0-9050b726084e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cmac_particle_flow' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cohesive='/content/cmac_particle_flow/images/Cohesive'\n",
        "easyflow='/content/cmac_particle_flow/images/Easyflowing'\n",
        "freeflow='/content/cmac_particle_flow/images/Freeflowing'"
      ],
      "metadata": {
        "id": "07RCuClT6xjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths=[]\n",
        "labels=[]\n",
        "import os\n",
        "\n",
        "for i in os.listdir(cohesive):\n",
        "  image_paths.append(os.path.join(cohesive,i))\n",
        "  labels.append(0)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "0JUbfmgK64LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(easyflow):\n",
        "  image_paths.append(os.path.join(easyflow,i))\n",
        "  labels.append(1)"
      ],
      "metadata": {
        "id": "h5VoNi7_64V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(freeflow):\n",
        "  image_paths.append(os.path.join(freeflow,i))\n",
        "  labels.append(2)"
      ],
      "metadata": {
        "id": "3JCDVL_r64Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "image_data = {'path': image_paths, 'label': labels}\n",
        "df = pd.DataFrame(data=image_data)"
      ],
      "metadata": {
        "id": "kyZEJv1W64cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_jJj5HC64fs",
        "outputId": "06beda66-fe29-400c-ad8c-0121429abdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 path  label\n",
            "0   /content/cmac_particle_flow/images/Cohesive/Az...      0\n",
            "1   /content/cmac_particle_flow/images/Cohesive/Pa...      0\n",
            "2   /content/cmac_particle_flow/images/Cohesive/1-...      0\n",
            "3   /content/cmac_particle_flow/images/Cohesive/Mo...      0\n",
            "4   /content/cmac_particle_flow/images/Cohesive/Li...      0\n",
            "..                                                ...    ...\n",
            "92  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "93  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "94  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "95  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "96  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "\n",
            "[97 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "UG63cQ4a7CDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label']=df['label'].map({0:'Cohesive',1:'Easyflow',2:'Freeflow'})"
      ],
      "metadata": {
        "id": "NG_Om_H77Gfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ],
      "metadata": {
        "id": "tccwMNYc7TPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an instance of the ImageDataGenerator for preprocessing the images\n",
        "data_gen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "# Create a train data generator from the train dataframe\n",
        "train_data_gen = data_gen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    x_col=\"path\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(384, 384),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Create a validation data generator from the validation dataframe\n",
        "val_data_gen = data_gen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    x_col=\"path\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(384, 384),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained Vision Transformer model\n",
        "vision_transformer = tf.keras.applications.vgg16.VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(384, 384, 3)\n",
        ")\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in vision_transformer.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add the classification head on top of the pre-trained layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        vision_transformer,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=43,\n",
        "    validation_data=val_data_gen,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "y2UlhaAS7I6o",
        "outputId": "88a2b85a-6df5-4100-c7d8-dc6434a4896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b34b53433b6b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create an instance of the ImageDataGenerator for preprocessing the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m data_gen = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "id": "1fazDpFVTulD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "Wc4ywEk0Scvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.models.load_model('path/to/your/model.h5')\n",
        "\n",
        "# Load and preprocess the input image\n",
        "image_path = '/content/cmac_particle_flow/images/Cohesive/Span 60_19mm.jpg'\n",
        "input_size = (384, 384)  # Adjust this to match the input size of your model\n",
        "\n",
        "# Load the image\n",
        "image = load_img(image_path, target_size=input_size)\n",
        "image = img_to_array(image)\n",
        "# image /= 255.0  # Apply the scaling factor\n",
        "\n",
        "# Expand dimensions to create a batch of size 1\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Preprocess the input image\n",
        "image = preprocess_input(image)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Decode the predictions\n",
        "# (Adjust this part based on the output format of your model)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "probability = np.max(predictions, axis=1)\n",
        "\n",
        "# Print the predicted class and probability\n",
        "print(f'Predicted Class: {predicted_class[0]}')\n",
        "print(f'Probability: {probability[0] * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "8C53-JiG7Olw",
        "outputId": "c067cbf1-dc7a-48bf-f14f-1e3c1c122159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8bf3dd8ed4a2>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Expand dimensions to create a batch of size 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Preprocess the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install timm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlEES9XubDdP",
        "outputId": "2c87dd56-f90e-44aa-ff2d-2048823ce8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm"
      ],
      "metadata": {
        "id": "khECZTTXZybS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHUeoSTSjUf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}