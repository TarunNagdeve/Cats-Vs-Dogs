{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwj32Mi3kI7F1mQiUGtTnY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarunNagdeve/Cats-Vs-Dogs/blob/master/Untitled72.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6qEM_Dl6n0m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers\n",
        "from keras.applications import EfficientNetB0\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def mark_points(image, points):\n",
        "    img = Image.open(image)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for point in points:\n",
        "        draw.rectangle([point[0] - 2, point[1] - 2, point[0] + 2, point[1] + 2], outline='red')\n",
        "\n",
        "    return img\n",
        "\n",
        "def main():\n",
        "    st.title(\"Mark Extreme Points on an Image\")\n",
        "    uploaded_file = st.file_uploader(\"Choose an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "        points = []\n",
        "        marked_image = None\n",
        "\n",
        "        if st.button(\"Mark Points\"):\n",
        "            marked_image = mark_points(uploaded_file, points)\n",
        "            st.image(marked_image, caption=\"Marked Image\", use_column_width=True)\n",
        "\n",
        "        click_coordinates = st.button(\"Click on Image to Add Point\")\n",
        "\n",
        "        if click_coordinates:\n",
        "            st.markdown(\n",
        "                \"\"\"\n",
        "                <style>\n",
        "                canvas { border: 1px solid black }\n",
        "                </style>\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "            st.write(\n",
        "                \"\"\"\n",
        "                <script>\n",
        "                const canvas = document.getElementsByTagName('canvas')[0];\n",
        "                const rect = canvas.getBoundingClientRect();\n",
        "                canvas.addEventListener('click', function(event) {\n",
        "                    const x = event.clientX - rect.left;\n",
        "                    const y = event.clientY - rect.top;\n",
        "                    const data = { x, y };\n",
        "                    const jsonString = JSON.stringify(data);\n",
        "                    Streamlit.connection.sendMessage(jsonString);\n",
        "                });\n",
        "                </script>\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "            if \"data\" not in st.session_state:\n",
        "                st.session_state.data = []\n",
        "\n",
        "            if st.session_state.data:\n",
        "                data = st.session_state.data\n",
        "                points.append((data[\"x\"], data[\"y\"]))\n",
        "                del st.session_state.data\n",
        "\n",
        "        if len(points) > 0:\n",
        "            st.write(\"### Marked Points\")\n",
        "            for i, point in enumerate(points):\n",
        "                st.write(f\"Point {i + 1}: ({point[0]}, {point[1]})\")\n",
        "\n",
        "    else:\n",
        "        st.warning(\"Please upload an image file.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "fBkUv_fcAc3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def mark_points(image, points):\n",
        "    img = Image.open(image)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for point in points:\n",
        "        draw.rectangle([point[0] - 2, point[1] - 2, point[0] + 2, point[1] + 2], outline='red')\n",
        "\n",
        "    return img\n",
        "\n",
        "def main():\n",
        "    st.title(\"Mark Extreme Points on an Image\")\n",
        "    uploaded_file = st.file_uploader(\"Choose an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "        points = []\n",
        "        marked_image = None\n",
        "\n",
        "        if st.button(\"Mark Points\"):\n",
        "            marked_image = mark_points(uploaded_file, points)\n",
        "            st.image(marked_image, caption=\"Marked Image\", use_column_width=True)\n",
        "\n",
        "        click_coordinates = st.button(\"Click on Image to Add Point\")\n",
        "\n",
        "        if click_coordinates:\n",
        "            clicked_x = st.session_state.mouse_click_x\n",
        "            clicked_y = st.session_state.mouse_click_y\n",
        "\n",
        "            if clicked_x and clicked_y:\n",
        "                points.append((clicked_x, clicked_y))\n",
        "\n",
        "        if len(points) > 0:\n",
        "            st.write(\"### Marked Points\")\n",
        "            for i, point in enumerate(points):\n",
        "                st.write(f\"Point {i + 1}: ({point[0]}, {point[1]})\")\n",
        "\n",
        "    else:\n",
        "        st.warning(\"Please upload an image file.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ZmSkVeN-_NJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def mark_points(image, points):\n",
        "    img = Image.open(image)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for point in points:\n",
        "        draw.rectangle([point[0] - 2, point[1] - 2, point[0] + 2, point[1] + 2], outline='red')\n",
        "\n",
        "    return img\n",
        "\n",
        "def main():\n",
        "    st.title(\"Mark Extreme Points on an Image\")\n",
        "    uploaded_file = st.file_uploader(\"Choose an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "        points = []\n",
        "        marked_image = None\n",
        "\n",
        "        if st.button(\"Mark Points\"):\n",
        "            marked_image = mark_points(uploaded_file, points)\n",
        "\n",
        "        col1, col2 = st.beta_columns(2)\n",
        "\n",
        "        with col1:\n",
        "            x = st.number_input(\"X Coordinate\", value=0)\n",
        "        with col2:\n",
        "            y = st.number_input(\"Y Coordinate\", value=0)\n",
        "\n",
        "        if st.button(\"Add Point\"):\n",
        "            points.append((x, y))\n",
        "\n",
        "        if marked_image is not None:\n",
        "            st.image(marked_image, caption=\"Marked Image\", use_column_width=True)\n",
        "\n",
        "        if len(points) > 0:\n",
        "            st.write(\"### Marked Points\")\n",
        "            for i, point in enumerate(points):\n",
        "                st.write(f\"Point {i + 1}: ({point[0]}, {point[1]})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "lZ-N04Ym9nTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the uploaded image\n",
        "        image_data = uploaded_file.getvalue()\n",
        "        image = np.array(bytearray(image_data), dtype=np.uint8)\n",
        "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Display the original image\n",
        "        st.image(image, channels=\"BGR\")\n",
        "\n",
        "        # Apply st_cropper to get the cropped image\n",
        "        cropped_image = st_cropper(image)\n",
        "\n",
        "        # Display the cropped image\n",
        "        if cropped_image is not None:\n",
        "            st.image(cropped_image, channels=\"BGR\")\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def st_cropper(image):\n",
        "    # Create a copy of the original image\n",
        "    image_copy = np.copy(image)\n",
        "\n",
        "    # Set the default cropped image to None\n",
        "    cropped_image = None\n",
        "\n",
        "    # Show the image using st.image\n",
        "    st.image(image_copy, channels=\"BGR\", use_column_width=True)\n",
        "\n",
        "    # Get the cropped coordinates using st_cropper\n",
        "    cropped_coords = st_cropper_widget(image_copy)\n",
        "\n",
        "    # Check if cropping is done\n",
        "    if cropped_coords is not None:\n",
        "        # Extract the coordinates\n",
        "        x1, y1, x2, y2 = cropped_coords\n",
        "\n",
        "        # Perform cropping\n",
        "        cropped_image = image_copy[y1:y2, x1:x2]\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "def st_cropper_widget(image):\n",
        "    # Generate a unique hash for the image\n",
        "    image_hash = st.hash(image.tobytes())\n",
        "\n",
        "    # Create a unique key for the widget\n",
        "    widget_key = f\"cropper_{image_hash}\"\n",
        "\n",
        "    # Get the cropped coordinates using st_cropper\n",
        "    cropped_coords = st_cropper(image, key=widget_key)\n",
        "\n",
        "    return cropped_coords\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ZzTfBSWixJL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "\n",
        "# Function to handle mouse events\n",
        "def mouse_callback(event, x, y, flags, param):\n",
        "    if event == cv2.EVENT_LBUTTONDOWN:\n",
        "        # Set the initial coordinates of the bounding box\n",
        "        param['x1'], param['y1'] = x, y\n",
        "        param['x2'], param['y2'] = x, y\n",
        "    elif event == cv2.EVENT_LBUTTONUP:\n",
        "        # Set the final coordinates of the bounding box\n",
        "        param['x2'], param['y2'] = x, y\n",
        "        # Display the cropped image\n",
        "        cropped_image = param['image'][param['y1']:param['y2'], param['x1']:param['x2']]\n",
        "        cv2.imshow('Cropped Image', cropped_image)\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "def main():\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the uploaded image\n",
        "        image_data = uploaded_file.getvalue()\n",
        "        image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Create a dictionary to store the coordinates\n",
        "        bbox_coords = {'x1': -1, 'y1': -1, 'x2': -1, 'y2': -1, 'image': image}\n",
        "\n",
        "        # Display the image\n",
        "        st.image(image)\n",
        "\n",
        "        # Set up the mouse callback function\n",
        "        cv2.namedWindow('Image')\n",
        "        cv2.setMouseCallback('Image', mouse_callback, bbox_coords)\n",
        "\n",
        "        # Wait for the user to select the bounding box\n",
        "        while True:\n",
        "            cv2.imshow('Image', image)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        # Close all windows\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "h9uU81B2hukr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    st.image(image)\n",
        "\n",
        "    bbox_x = st.slider(\"Bounding Box X\", 0, image.shape[1], 0)\n",
        "    bbox_y = st.slider(\"Bounding Box Y\", 0, image.shape[0], 0)\n",
        "    bbox_width = st.slider(\"Bounding Box Width\", 0, image.shape[1] - bbox_x, 100)\n",
        "    bbox_height = st.slider(\"Bounding Box Height\", 0, image.shape[0] - bbox_y, 100)\n",
        "\n",
        "    if st.button(\"Crop\"):\n",
        "        cropped_image = image[bbox_y:bbox_y+bbox_height, bbox_x:bbox_x+bbox_width]\n",
        "        st.image(cropped_image)\n"
      ],
      "metadata": {
        "id": "bnna87iQg7ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# Set page title\n",
        "st.set_page_config(page_title=\"Image Coordinate Extraction\")\n",
        "\n",
        "# Upload image\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# Check if image is uploaded\n",
        "if uploaded_file is not None:\n",
        "    # Open the uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "\n",
        "    # Display the uploaded image\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    # Get the image size\n",
        "    image_width, image_height = image.size\n",
        "\n",
        "    # Create a drawing object\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Track clicked coordinates\n",
        "    clicked_coordinates = []\n",
        "\n",
        "    # Mouse click event handler\n",
        "    def on_mouse_click(x, y, button, _):\n",
        "        if button == \"left\":\n",
        "            # Save the clicked coordinates\n",
        "            clicked_coordinates.append((x, y))\n",
        "\n",
        "            # Draw a point at the clicked coordinates\n",
        "            draw.point((x, y), fill=\"red\")\n",
        "\n",
        "            # Update the displayed image with the marked point\n",
        "            st.image(image, caption=\"Marked Image\", use_column_width=True)\n",
        "\n",
        "            # Print the clicked coordinates\n",
        "            st.write(f\"Clicked Coordinate: ({x}, {y})\")\n",
        "\n",
        "    # Register the mouse click event handler\n",
        "    st.image(image, caption=\"Click on extreme points\", use_column_width=True, format=\"PNG\", output_format=\"PNG\", use_column_width=True)\n",
        "    st_canvas = st.image(image, use_column_width=True, format='PNG')\n",
        "    st_canvas._get_coordinates = True\n",
        "    st_canvas._recorded_coords = []\n",
        "    st_canvas.add_mouse_callback(on_mouse_click)\n"
      ],
      "metadata": {
        "id": "h6p6rMXsPdTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import streamlit as st\n",
        "\n",
        "# Function to read the uploaded image using OpenCV\n",
        "def read_image(uploaded_image):\n",
        "    # Convert the uploaded image to numpy array\n",
        "    image_array = np.asarray(uploaded_image)\n",
        "\n",
        "    # Convert the image to BGR format (required by OpenCV)\n",
        "    image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return image_bgr\n",
        "\n",
        "# Main function to run the Streamlit app\n",
        "def main():\n",
        "    # Title and file upload section\n",
        "    st.title(\"Image Processing\")\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    # Check if an image is uploaded\n",
        "    if uploaded_file is not None:\n",
        "        # Read the uploaded image using OpenCV\n",
        "        image = read_image(uploaded_file)\n",
        "\n",
        "        # Display the uploaded image\n",
        "        st.image(image, channels=\"BGR\")\n",
        "\n",
        "        # Mouse callback function\n",
        "        def mouse_callback(event, x, y, flags, param):\n",
        "            if event == cv2.EVENT_LBUTTONDOWN:\n",
        "                print(f\"Clicked at x={x}, y={y}\")\n",
        "\n",
        "        # Set the mouse callback\n",
        "        cv2.namedWindow(\"Image\")\n",
        "        cv2.setMouseCallback(\"Image\", mouse_callback)\n",
        "\n",
        "        # Wait for any key to be pressed\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "        # Close the OpenCV windows\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "UXSTQYcyqbLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def main():\n",
        "    # Global variables\n",
        "    image = None\n",
        "    click_coordinates = []\n",
        "\n",
        "    st.title(\"Extreme Coordinates Extraction\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the image file\n",
        "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Display the image\n",
        "        st.image(image, channels=\"BGR\", use_column_width=True)\n",
        "\n",
        "        # Button to start capturing coordinates\n",
        "        capture_button = st.button(\"Capture Coordinates\")\n",
        "\n",
        "        if capture_button:\n",
        "            # Create a plotly figure for displaying the image and capturing clicks\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=[],\n",
        "                    y=[],\n",
        "                    mode=\"markers\",\n",
        "                    marker=dict(size=10, color=\"red\")\n",
        "                )\n",
        "            )\n",
        "\n",
        "            fig.update_layout(\n",
        "                images=[\n",
        "                    go.layout.Image(\n",
        "                        source=image,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"y\",\n",
        "                        x=0,\n",
        "                        y=0,\n",
        "                        sizex=image.shape[1],\n",
        "                        sizey=image.shape[0],\n",
        "                        sizing=\"stretch\",\n",
        "                        layer=\"below\"\n",
        "                    )\n",
        "                ],\n",
        "                showlegend=False,\n",
        "                width=image.shape[1],\n",
        "                height=image.shape[0],\n",
        "                margin=dict(l=0, r=0, t=0, b=0)\n",
        "            )\n",
        "\n",
        "            # Render the plotly figure\n",
        "            plotly_figure = st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Wait for user clicks\n",
        "            while plotly_figure.active:\n",
        "                # Get the click coordinates from the plotly figure\n",
        "                if st.button(\"Capture Point\"):\n",
        "                    click_data = plotly_figure.json_data[\"props\"][\"figure\"][\"data\"][0][\"x\"], \\\n",
        "                                 plotly_figure.json_data[\"props\"][\"figure\"][\"data\"][0][\"y\"]\n",
        "                    click_coordinates.append(click_data)\n",
        "\n",
        "            # Display the captured coordinates\n",
        "            if click_coordinates:\n",
        "                st.subheader(\"Captured Coordinates:\")\n",
        "                for i, (x, y) in enumerate(click_coordinates):\n",
        "                    st.write(f\"Point {i + 1}: x={x}, y={y}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "AhnwbBDPlsL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSu4c4qtqAL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    # Global variables\n",
        "    image = None\n",
        "    click_coordinates = []\n",
        "\n",
        "    def click_event(event):\n",
        "        nonlocal click_coordinates\n",
        "\n",
        "        if event.button == 1:  # Left mouse button\n",
        "            x, y = int(event.xdata), int(event.ydata)\n",
        "            click_coordinates.append((x, y))\n",
        "\n",
        "    # Upload image\n",
        "    st.title(\"Extreme Coordinates Extraction\")\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the image\n",
        "        image = plt.imread(uploaded_file)\n",
        "\n",
        "        # Create a new figure and display the image\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.imshow(image)\n",
        "\n",
        "        # Register the mouse click event\n",
        "        fig.canvas.mpl_connect(\"button_press_event\", click_event)\n",
        "\n",
        "        # Display the image using Streamlit\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Convert the click coordinates to numpy array\n",
        "        click_coordinates = np.array(click_coordinates)\n",
        "\n",
        "        # Print the extreme coordinates\n",
        "        st.subheader(\"Extreme Coordinates:\")\n",
        "        for coordinate in click_coordinates:\n",
        "            x, y = coordinate\n",
        "            st.write(f\"x: {x}, y: {y}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "a4xQUlKyjLgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Global variables\n",
        "image = None\n",
        "click_coordinates = []\n",
        "\n",
        "def click_event(event):\n",
        "    global click_coordinates\n",
        "\n",
        "    if event.button == 1:  # Left mouse button\n",
        "        x, y = int(event.xdata), int(event.ydata)\n",
        "        click_coordinates.append((x, y))\n",
        "\n",
        "def main():\n",
        "    global image, click_coordinates\n",
        "\n",
        "    # Upload image\n",
        "    st.title(\"Extreme Coordinates Extraction\")\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the image\n",
        "        image = plt.imread(uploaded_file)\n",
        "\n",
        "        # Create a new figure and display the image\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.imshow(image)\n",
        "\n",
        "        # Register the mouse click event\n",
        "        fig.canvas.mpl_connect(\"button_press_event\", click_event)\n",
        "\n",
        "        # Display the image using Streamlit\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Convert the click coordinates to numpy array\n",
        "        click_coordinates = np.array(click_coordinates)\n",
        "\n",
        "        # Print the extreme coordinates\n",
        "        st.subheader(\"Extreme Coordinates:\")\n",
        "        for coordinate in click_coordinates:\n",
        "            x, y = coordinate\n",
        "            st.write(f\"x: {x}, y: {y}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "MztnuWDFhWwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fKeC0j8jJEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Global variables\n",
        "image = None\n",
        "click_coordinates = []\n",
        "\n",
        "def click_event(event):\n",
        "    global click_coordinates\n",
        "\n",
        "    if event.button == 1:  # Left mouse button\n",
        "        x, y = int(event.xdata), int(event.ydata)\n",
        "        click_coordinates.append((x, y))\n",
        "\n",
        "def main():\n",
        "    global image, click_coordinates\n",
        "\n",
        "    # Load the image\n",
        "    image_path = \"path/to/your/image.jpg\"\n",
        "    image = plt.imread(image_path)\n",
        "\n",
        "    # Create a new figure and display the image\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Register the mouse click event\n",
        "    fig.canvas.mpl_connect(\"button_press_event\", click_event)\n",
        "\n",
        "    # Display the image and wait for user interaction\n",
        "    plt.show()\n",
        "\n",
        "    # Convert the click coordinates to numpy array\n",
        "    click_coordinates = np.array(click_coordinates)\n",
        "\n",
        "    # Print the extreme coordinates\n",
        "    print(\"Extreme Coordinates:\")\n",
        "    for coordinate in click_coordinates:\n",
        "        x, y = coordinate\n",
        "        print(f\"x: {x}, y: {y}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "hUswITcffMnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Global variables\n",
        "image = None\n",
        "click_coordinates = []\n",
        "\n",
        "def click_event(event):\n",
        "    global click_coordinates\n",
        "\n",
        "    if event.button == 1:  # Left mouse button\n",
        "        x, y = event.x, event.y\n",
        "        click_coordinates.append((x, y))\n",
        "\n",
        "def main():\n",
        "    global image, click_coordinates\n",
        "\n",
        "    # Load the image\n",
        "    image_path = \"path/to/your/image.jpg\"\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Create a copy of the image for display\n",
        "    image_display = image.copy()\n",
        "\n",
        "    # Display the image\n",
        "    image_display.show()\n",
        "\n",
        "    # Get the image dimensions\n",
        "    width, height = image_display.size\n",
        "\n",
        "    # Create a new image with mouse events\n",
        "    image_with_events = Image.new(\"RGB\", (width, height))\n",
        "    image_with_events.paste(image, (0, 0))\n",
        "\n",
        "    # Register the mouse click event\n",
        "    image_with_events.show(title=\"Click on Extreme Coordinates\")\n",
        "    image_with_events.canvas.mpl_connect(\"button_press_event\", click_event)\n",
        "\n",
        "    # Wait for user to close the image\n",
        "    input(\"Press Enter after selecting coordinates...\")\n",
        "\n",
        "    # Convert the click coordinates to numpy array\n",
        "    click_coordinates = np.array(click_coordinates)\n",
        "\n",
        "    # Print the extreme coordinates\n",
        "    print(\"Extreme Coordinates:\")\n",
        "    for coordinate in click_coordinates:\n",
        "        x, y = coordinate\n",
        "        print(f\"x: {x}, y: {y}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "rpznPhxgeZll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "from streamlit_drawable_canvas import st_canvas\n",
        "\n",
        "def main():\n",
        "    st.title(\"Click on Extreme Coordinates\")\n",
        "    st.write(\"Select the extreme points on the input image\")\n",
        "\n",
        "    # Upload image file\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the uploaded image\n",
        "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "        image = cv2.imdecode(file_bytes, 1)\n",
        "\n",
        "        # Display the image\n",
        "        st.image(image, channels=\"BGR\", caption=\"Uploaded Image\")\n",
        "\n",
        "        # Create a canvas to draw on the image\n",
        "        canvas_image = st_canvas(\n",
        "            fill_color=\"rgba(255, 0, 0, 0.3)\",  # Set drawing color and opacity\n",
        "            stroke_width=2,\n",
        "            stroke_color=\"red\",\n",
        "            background_image=image,\n",
        "            update_streamlit=True,\n",
        "            height=image.shape[0],  # Set canvas height same as image\n",
        "            drawing_mode=\"freedraw\",\n",
        "            key=\"canvas\",\n",
        "        )\n",
        "\n",
        "        # Get the drawn coordinates\n",
        "        if canvas_image is not None:\n",
        "            # Convert to grayscale\n",
        "            gray_image = cv2.cvtColor(canvas_image.astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Get non-zero pixel coordinates\n",
        "            coordinates = np.argwhere(gray_image > 0)\n",
        "\n",
        "            # Display the clicked coordinates\n",
        "            st.write(\"Clicked Coordinates:\")\n",
        "            for coordinate in coordinates:\n",
        "                x, y = coordinate[1], coordinate[0]  # Swap x and y coordinates\n",
        "                st.write(f\"x: {x}, y: {y}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "7c-3eQ74cex_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from streamlit_cropper import st_cropper\n",
        "\n",
        "def main():\n",
        "    # Set up Streamlit layout\n",
        "    st.title(\"Click Extreme Points on Image\")\n",
        "    st.sidebar.header(\"Image Selection\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.sidebar.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    # Display uploaded image\n",
        "    if uploaded_image is not None:\n",
        "        image = Image.open(uploaded_image)\n",
        "        st.image(image)\n",
        "\n",
        "        # Get cropped image\n",
        "        cropped_image = st_cropper(image)\n",
        "\n",
        "        # Display the coordinates of the cropped area\n",
        "        st.sidebar.write(f\"Cropped Area: {cropped_image}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "gh93CsbI3o7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from streamlit_cropper import st_cropper\n",
        "\n",
        "def main():\n",
        "    st.title(\"Corner Coordinate Logger\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Read the uploaded image\n",
        "        image = read_image(uploaded_image)\n",
        "\n",
        "        # Display the original image\n",
        "        st.image(image, caption=\"Original Image\")\n",
        "\n",
        "        # Crop the image and get the coordinates\n",
        "        cropped_image, (top_left, bottom_right) = st_cropper(image, box_color=(255, 0, 0), box_thickness=2)\n",
        "\n",
        "        # Display the cropped image\n",
        "        st.image(cropped_image, caption=\"Cropped Image\")\n",
        "\n",
        "        # Display the coordinates\n",
        "        st.write(f\"Top-Left Corner: {top_left}\")\n",
        "        st.write(f\"Bottom-Right Corner: {bottom_right}\")\n",
        "\n",
        "def read_image(image):\n",
        "    # Read the image using the appropriate library (e.g., PIL, OpenCV, etc.)\n",
        "    # Return the image as a numpy array or PIL Image object\n",
        "    return image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "1Ygvoq9bfP_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########hey\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    st.title(\"Click on Extreme Coordinates\")\n",
        "    st.write(\"Select the extreme points on the input image\")\n",
        "\n",
        "    # Upload image file\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the uploaded image\n",
        "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "        image = cv2.imdecode(file_bytes, 1)\n",
        "\n",
        "        # Display the image\n",
        "        st.image(image, channels=\"BGR\", caption=\"Uploaded Image\")\n",
        "\n",
        "        # Get extreme coordinates on image click\n",
        "        st.write(\"Click on the extreme points of the object:\")\n",
        "        clicked_points = st.image_processing_tools.drawing_canvas(\n",
        "            image,\n",
        "            tool=\"point\",\n",
        "            color=\"red\",\n",
        "            drawing_mode=\"freedraw\",\n",
        "            key=\"canvas\",\n",
        "        )\n",
        "\n",
        "        # Display the clicked coordinates\n",
        "        if clicked_points is not None:\n",
        "            st.write(\"Clicked Coordinates:\")\n",
        "            for point in clicked_points:\n",
        "                st.write(f\"x: {point['x']}, y: {point['y']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Cb4mJTAobJMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from streamlit_cropper import st_cropper\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Cropper\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Read the uploaded image using OpenCV\n",
        "        image = read_image(uploaded_image)\n",
        "\n",
        "        # Display the original image\n",
        "        st.image(image, caption=\"Original Image\")\n",
        "\n",
        "        # Use st_cropper to crop the image\n",
        "        cropped_image, coords = st_cropper(image, realtime_update=True, box_color=(255, 0, 0))\n",
        "\n",
        "        # Display the cropped image\n",
        "        st.image(cropped_image, caption=\"Cropped Image\")\n",
        "\n",
        "        # Get the extreme points coordinates\n",
        "        min_x, min_y = coords[0]\n",
        "        max_x, max_y = coords[1]\n",
        "\n",
        "        # Display the coordinates\n",
        "        st.write(\"Top Left Coordinate: ({}, {})\".format(min_x, min_y))\n",
        "        st.write(\"Bottom Right Coordinate: ({}, {})\".format(max_x, max_y))\n",
        "\n",
        "def read_image(image_file):\n",
        "    image_data = image_file.read()\n",
        "    image_array = np.frombuffer(image_data, np.uint8)\n",
        "    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Hr2JzU8Q1gIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Cropper\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Read the uploaded image using OpenCV\n",
        "        image = read_image(uploaded_image)\n",
        "\n",
        "        # Display the original image\n",
        "        st.image(image, caption=\"Original Image\")\n",
        "\n",
        "        # Draw a rectangular selection to crop the image\n",
        "        cropped_image = st_cropper(image)\n",
        "\n",
        "        # Display the cropped image\n",
        "        st.image(cropped_image, caption=\"Cropped Image\")\n",
        "\n",
        "def read_image(image_file):\n",
        "    image_data = np.fromstring(image_file.read(), np.uint8)\n",
        "    image = cv2.imdecode(image_data, cv2.IMREAD_UNCHANGED)\n",
        "    return image\n",
        "\n",
        "def st_cropper(image):\n",
        "    image_copy = image.copy()\n",
        "    height, width = image_copy.shape[:2]\n",
        "\n",
        "    # Create a blank mask image\n",
        "    mask = np.zeros_like(image_copy)\n",
        "\n",
        "    # Draw a rectangular selection using mouse events\n",
        "    rect_start = None\n",
        "    rect_end = None\n",
        "    rect_color = (0, 255, 0)  # Green color\n",
        "\n",
        "    def mouse_callback(event, x, y, flags, param):\n",
        "        nonlocal rect_start, rect_end\n",
        "\n",
        "        if event == cv2.EVENT_LBUTTONDOWN:\n",
        "            rect_start = (x, y)\n",
        "\n",
        "        elif event == cv2.EVENT_LBUTTONUP:\n",
        "            rect_end = (x, y)\n",
        "            cv2.rectangle(mask, rect_start, rect_end, (255, 255, 255), -1)\n",
        "\n",
        "    cv2.namedWindow(\"Cropping\")\n",
        "    cv2.setMouseCallback(\"Cropping\", mouse_callback)\n",
        "\n",
        "    # Keep updating the display until cropping is done\n",
        "    while True:\n",
        "        # Apply the mask to the image to show the rectangular selection\n",
        "        image_with_mask = cv2.addWeighted(image_copy, 0.7, mask, 0.3, 0)\n",
        "\n",
        "        # Display the image with mask\n",
        "        cv2.imshow(\"Cropping\", image_with_mask)\n",
        "\n",
        "        # Press 'Esc' key to finish cropping\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "        if key == 27:\n",
        "            break\n",
        "\n",
        "    # Close the cropping window\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Apply the mask to the original image to get the cropped image\n",
        "    cropped_image = cv2.bitwise_and(image_copy, mask)\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "LVP1S4Q5LRM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wiTuj89bZA8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Cropper\")\n",
        "\n",
        "    # Upload image file\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Load image\n",
        "        image = Image.open(uploaded_file)\n",
        "\n",
        "        # Display image\n",
        "        st.image(image, caption=\"Original Image\")\n",
        "\n",
        "        # Get user input points\n",
        "        cropped_image = get_cropped_image(image)\n",
        "\n",
        "        # Display cropped image\n",
        "        st.image(cropped_image, caption=\"Cropped Image\")\n",
        "\n",
        "def get_cropped_image(image):\n",
        "    # Create copy of the original image\n",
        "    image_copy = image.copy()\n",
        "\n",
        "    # Create image draw object\n",
        "    draw = ImageDraw.Draw(image_copy)\n",
        "\n",
        "    # Display instructions to user\n",
        "    st.write(\"Instructions:\")\n",
        "    st.write(\"1. Click on the top-left corner of the desired crop region.\")\n",
        "    st.write(\"2. Click on the bottom-right corner of the desired crop region.\")\n",
        "    st.write(\"3. The cropped image will be displayed below.\")\n",
        "\n",
        "    # Get user input points\n",
        "    with st.beta_expander(\"Image with Crop Points\"):\n",
        "        # Display image for user input\n",
        "        st.image(image_copy, use_column_width=True, caption=\"Select the crop points\")\n",
        "\n",
        "        # Get crop points\n",
        "        crop_points = st.session_state.get(\"crop_points\", [])\n",
        "\n",
        "        if len(crop_points) < 2:\n",
        "            # Wait for user clicks\n",
        "            event_result = st.pydeck_chart(screenshot=\"True\", use_container_width=True)\n",
        "            if event_result:\n",
        "                x, y = event_result[\"layers\"][0][\"data\"][\"lat\"][0], event_result[\"layers\"][0][\"data\"][\"lon\"][0]\n",
        "                crop_points.append((x, y))\n",
        "                st.session_state[\"crop_points\"] = crop_points\n",
        "\n",
        "        # Draw rectangle on the image\n",
        "        if len(crop_points) == 2:\n",
        "            draw.rectangle([crop_points[0], crop_points[1]], outline=\"red\")\n",
        "\n",
        "    # Crop the image\n",
        "    if len(crop_points) == 2:\n",
        "        cropped_image = image.crop([crop_points[0][0], crop_points[0][1], crop_points[1][0], crop_points[1][1]])\n",
        "        return cropped_image\n",
        "\n",
        "    return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "OI39Sz-fZDib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Cropper\")\n",
        "\n",
        "    # Upload image file\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Load image\n",
        "        image = Image.open(uploaded_file)\n",
        "\n",
        "        # Display image\n",
        "        st.image(image, caption=\"Original Image\")\n",
        "\n",
        "        # Get user input points\n",
        "        cropped_image = get_cropped_image(image)\n",
        "\n",
        "        # Display cropped image\n",
        "        st.image(cropped_image, caption=\"Cropped Image\")\n",
        "\n",
        "def get_cropped_image(image):\n",
        "    # Create copy of the original image\n",
        "    image_copy = image.copy()\n",
        "\n",
        "    # Create image draw object\n",
        "    draw = ImageDraw.Draw(image_copy)\n",
        "\n",
        "    # Display instructions to user\n",
        "    st.write(\"Instructions:\")\n",
        "    st.write(\"1. Click on the top-left corner of the desired crop region.\")\n",
        "    st.write(\"2. Click on the bottom-right corner of the desired crop region.\")\n",
        "    st.write(\"3. The cropped image will be displayed below.\")\n",
        "\n",
        "    # Get user input points\n",
        "    crop_points = st.session_state.get(\"crop_points\", [])\n",
        "\n",
        "    if len(crop_points) < 2:\n",
        "        # Wait for user clicks\n",
        "        clicked_positions = st.image(image_copy, use_column_width=True, caption=\"Select the crop points\", format=\"PNG\")\n",
        "\n",
        "        if clicked_positions is not None:\n",
        "            # Store the clicked positions\n",
        "            if \"coordinates\" in clicked_positions:\n",
        "                crop_points.append(clicked_positions[\"coordinates\"])\n",
        "                st.session_state[\"crop_points\"] = crop_points\n",
        "\n",
        "    # Draw rectangle on the image\n",
        "    if len(crop_points) == 2:\n",
        "        draw.rectangle([crop_points[0], crop_points[1]], outline=\"red\")\n",
        "\n",
        "    # Crop the image\n",
        "    if len(crop_points) == 2:\n",
        "        cropped_image = image.crop((crop_points[0][0], crop_points[0][1], crop_points[1][0], crop_points[1][1]))\n",
        "        return cropped_image\n",
        "\n",
        "    return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "2oTIuWOUZ8Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Cropper\")\n",
        "\n",
        "    # Upload image file\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Load image\n",
        "        image = Image.open(uploaded_file)\n",
        "\n",
        "        # Display image\n",
        "        st.image(image, caption=\"Original Image\")\n",
        "\n",
        "        # Get user input points\n",
        "        cropped_image = get_cropped_image(image)\n",
        "\n",
        "        # Display cropped image\n",
        "        st.image(cropped_image, caption=\"Cropped Image\")\n",
        "\n",
        "def get_cropped_image(image):\n",
        "    # Create copy of the original image\n",
        "    image_copy = image.copy()\n",
        "\n",
        "    # Create image draw object\n",
        "    draw = ImageDraw.Draw(image_copy)\n",
        "\n",
        "    # Display instructions to user\n",
        "    st.write(\"Instructions:\")\n",
        "    st.write(\"1. Click on the top-left corner of the desired crop region.\")\n",
        "    st.write(\"2. Click on the bottom-right corner of the desired crop region.\")\n",
        "    st.write(\"3. The cropped image will be displayed below.\")\n",
        "\n",
        "    # Get user input points\n",
        "    crop_points = st.session_state.get(\"crop_points\", [])\n",
        "\n",
        "    if len(crop_points) < 2:\n",
        "        # Wait for user clicks\n",
        "        clicked_positions = st.image(image_copy, use_column_width=True, caption=\"Select the crop points\", format=\"PNG\")\n",
        "\n",
        "        if st.button(\"Click to capture point\"):\n",
        "            # Store the clicked positions\n",
        "            crop_points.append(st.session_state.cursor_xy)\n",
        "            st.session_state[\"crop_points\"] = crop_points\n",
        "\n",
        "    # Draw rectangle on the image\n",
        "    if len(crop_points) == 2:\n",
        "        draw.rectangle([crop_points[0], crop_points[1]], outline=\"red\")\n",
        "\n",
        "    # Crop the image\n",
        "    if len(crop_points) == 2:\n",
        "        cropped_image = image.crop((crop_points[0][0], crop_points[0][1], crop_points[1][0], crop_points[1][1]))\n",
        "        return cropped_image\n",
        "\n",
        "    return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9MgXaXU4kor1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "def main():\n",
        "    st.title(\"Corner Coordinate Logger\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Convert uploaded image to PIL Image object\n",
        "        pil_image = Image.open(uploaded_image)\n",
        "\n",
        "        # Display the uploaded image\n",
        "        st.image(pil_image, use_column_width=True)\n",
        "\n",
        "        # Get the coordinates of the corners\n",
        "        top_left, bottom_right = st_cropper(pil_image)\n",
        "\n",
        "        # Display the coordinates\n",
        "        st.write(f\"Top-Left Corner: {top_left}\")\n",
        "        st.write(f\"Bottom-Right Corner: {bottom_right}\")\n",
        "\n",
        "def st_cropper(image):\n",
        "    # Add code for cropper component here\n",
        "    # Implement the logic to get the coordinates of the corners\n",
        "    # Return the coordinates as top_left and bottom_right\n",
        "    top_left = (0, 0)  # Placeholder for top-left corner\n",
        "    bottom_right = (image.width, image.height)  # Placeholder for bottom-right corner\n",
        "    return top_left, bottom_right\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "gBQBVITwecZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Perform text detection\n",
        "text_detector = cv2.text.TextDetectorCNN_create(\"path/to/opencv_text_detection.pb\")\n",
        "_, text_regions = text_detector.detect(blur)\n",
        "\n",
        "# Create a mask for the text regions\n",
        "text_mask = np.zeros_like(gray)\n",
        "for region in text_regions:\n",
        "    x, y, w, h = region[0]\n",
        "    cv2.rectangle(text_mask, (x, y), (x + w, y + h), (255), cv2.FILLED)\n",
        "\n",
        "# Find contours excluding text regions\n",
        "contours, _ = cv2.findContours(cv2.bitwise_not(text_mask), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Draw contours on the original image\n",
        "contour_image = cv2.drawContours(image.copy(), contours, contourIdx=-1, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Text and Contour Detection', np.hstack((image, contour_image)))\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "qUjgrC6KVLqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "\n",
        "def main():\n",
        "    # Set up Streamlit layout\n",
        "    st.title(\"Click Extreme Points on Image\")\n",
        "    st.sidebar.header(\"Image Selection\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.sidebar.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    # Display uploaded image\n",
        "    if uploaded_image is not None:\n",
        "        image = cv2.imdecode(np.fromstring(uploaded_image.read(), np.uint8), 1)\n",
        "        st.image(image, channels=\"BGR\")\n",
        "\n",
        "        # Get image shape\n",
        "        height, width, _ = image.shape\n",
        "\n",
        "        # Create a canvas to display clicked points\n",
        "        canvas = st.image(np.zeros_like(image, dtype=np.uint8), width=width, channels=\"BGR\", use_column_width=True)\n",
        "\n",
        "        # Initialize list to store clicked points\n",
        "        clicked_points = []\n",
        "\n",
        "        # Function to handle mouse clicks on the image\n",
        "        def handle_click_event(event, x, y, flags, param):\n",
        "            if event == cv2.EVENT_LBUTTONDOWN:\n",
        "                # Add clicked point to the list\n",
        "                clicked_points.append((x, y))\n",
        "\n",
        "                # Draw a circle at the clicked point on the canvas\n",
        "                cv2.circle(canvas.image, (x, y), 5, (0, 0, 255), -1)\n",
        "\n",
        "                # Update the displayed image\n",
        "                canvas.image = cv2.cvtColor(canvas.image, cv2.COLOR_BGR2RGB)\n",
        "                canvas.image_widget.value = canvas.image\n",
        "\n",
        "                # Display the coordinates of the clicked point\n",
        "                st.sidebar.write(f\"Clicked Point: ({x}, {y})\")\n",
        "\n",
        "        # Set up mouse click event listener\n",
        "        cv2.namedWindow(\"Image\")\n",
        "        cv2.setMouseCallback(\"Image\", handle_click_event)\n",
        "\n",
        "        # Wait for user to click on the image\n",
        "        while len(clicked_points) < 2:\n",
        "            cv2.imshow(\"Image\", image)\n",
        "            cv2.waitKey(1)\n",
        "\n",
        "        # Close the OpenCV windows\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "    else:\n",
        "        st.write(\"Please upload an image on the sidebar\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "J0E2b8m_08QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from streamlit_canvas import st_canvas\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    # Set up Streamlit layout\n",
        "    st.title(\"Click Extreme Points on Image\")\n",
        "    st.sidebar.header(\"Image Selection\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.sidebar.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    # Display uploaded image\n",
        "    if uploaded_image is not None:\n",
        "        image = np.array(Image.open(uploaded_image))\n",
        "        st.image(image)\n",
        "\n",
        "        # Get image shape\n",
        "        height, width, _ = image.shape\n",
        "\n",
        "        # Create a canvas to display clicked points\n",
        "        canvas_result = st_canvas(\n",
        "            fill_color=\"rgba(255, 0, 0, 0.3)\",  # Red color with opacity\n",
        "            stroke_width=2,\n",
        "            stroke_color=\"rgba(255, 0, 0, 1)\",  # Red color\n",
        "            background_color=\"rgba(0, 0, 0, 0)\",  # Transparent background\n",
        "            height=height,\n",
        "            width=width,\n",
        "            drawing_mode=\"freedraw\",\n",
        "            key=\"canvas\",\n",
        "        )\n",
        "\n",
        "        # Initialize list to store clicked points\n",
        "        clicked_points = []\n",
        "\n",
        "        # Function to handle button click event\n",
        "        def handle_button_click():\n",
        "            st.sidebar.write(f\"Clicked Points: {clicked_points}\")\n",
        "\n",
        "        # Wait for user to click on the image\n",
        "        while len(clicked_points) < 2:\n",
        "            # Keep the app running without blocking\n",
        "            clicked_points = canvas_result.json_data[\"objects\"][0][\"data\"]\n",
        "            st.sidebar.write(\"Waiting for points...\")\n",
        "            st.sidebar.write(f\"Clicked Points: {clicked_points}\")\n",
        "            st.empty()\n",
        "\n",
        "        # Display the coordinates of the clicked points\n",
        "        st.sidebar.write(f\"Clicked Points: {clicked_points}\")\n",
        "        st.sidebar.button(\"Submit\", on_click=handle_button_click)\n",
        "\n",
        "    else:\n",
        "        st.write(\"Please upload an image on the sidebar\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "EPyZzTUO2n6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Perform text detection\n",
        "text_detection = cv2.text.detectText(blur, cv2.text.OCR_KNN_MODEL)\n",
        "\n",
        "# Get the detected text regions\n",
        "text_regions = text_detection[0]\n",
        "\n",
        "# Create a mask for the text regions\n",
        "text_mask = cv2.drawContours(\n",
        "    np.zeros_like(gray), text_regions, contourIdx=-1, color=255, thickness=cv2.FILLED\n",
        ")\n",
        "\n",
        "# Find contours excluding text regions\n",
        "contours, _ = cv2.findContours(cv2.bitwise_not(text_mask), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Draw contours on the original image\n",
        "contour_image = cv2.drawContours(image.copy(), contours, contourIdx=-1, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow('Text and Contour Detection', np.hstack((image, contour_image)))\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "06PNtj1HUN9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Coordinates App\")\n",
        "\n",
        "    # Upload the image\n",
        "    uploaded_file = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Display the image with coordinates\n",
        "        coords = st.image_coordinates(uploaded_file, key=\"image\")\n",
        "\n",
        "        if st.button(\"Save Point\") and coords is not None:\n",
        "            coords_list = st.session_state.get(\"coords_list\", [])\n",
        "            coords_list.append(coords)\n",
        "            st.session_state[\"coords_list\"] = coords_list\n",
        "\n",
        "        if coords is not None:\n",
        "            st.write(\"Clicked Coordinates:\", coords)\n",
        "\n",
        "        coords_list = st.session_state.get(\"coords_list\", [])\n",
        "        if coords_list:\n",
        "            st.write(\"All Clicked Coordinates:\")\n",
        "            for i, coord in enumerate(coords_list):\n",
        "                st.write(f\"Point {i+1}: {coord}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "q0_dJVB1xwKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "def process_image(image):\n",
        "    # Convert the image bytes to a numpy array\n",
        "    nparr = np.frombuffer(image.read(), np.uint8)\n",
        "\n",
        "    # Decode the numpy array to an image\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image (e.g., resize, normalize, etc.)\n",
        "    # ...\n",
        "\n",
        "    return img\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1 = request.files['image1']\n",
        "    image2 = request.files['image2']\n",
        "\n",
        "    # Process the images\n",
        "    processed_image1 = process_image(image1)\n",
        "    processed_image2 = process_image(image2)\n",
        "\n",
        "    # Perform prediction using the loaded model and the processed images\n",
        "    prediction = model.predict([processed_image1, processed_image2])\n",
        "\n",
        "    # Create a dataframe of the predicted values\n",
        "    df = pd.DataFrame(prediction, columns=['Predicted Values'])\n",
        "\n",
        "    # Return the dataframe as JSON response\n",
        "    return df.to_json()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Prepare the image files as bytes\n",
        "    image_bytes1 = uploaded_image1.read()\n",
        "    image_bytes2 = uploaded_image2.read()\n",
        "\n",
        "    # Send the image bytes to the API\n",
        "    files = {'image1': ('image1.jpg', io.BytesIO(image_bytes1), 'image/jpeg'),\n",
        "             'image2': ('image2.jpg', io.BytesIO(image_bytes2), 'image/jpeg')}\n",
        "    response = requests.post(API_URL, files=files)\n",
        "\n",
        "    # Convert the JSON response to a dataframe\n",
        "    df = pd.read_json(response.content)\n",
        "\n",
        "    # Display the dataframe\n",
        "    st.write('Predicted Values:')\n",
        "    st.dataframe(df)\n"
      ],
      "metadata": {
        "id": "j1PaNi1IPaLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def select_roi(image):\n",
        "    st.image(image, use_column_width=True)\n",
        "\n",
        "    st.header(\"Select Region of Interest (ROI)\")\n",
        "    st.write(\"Please follow the instructions below to select the extreme coordinates of the ROI:\")\n",
        "\n",
        "    st.markdown(\"1. Click on the **top-left** corner of the ROI.\")\n",
        "    st.markdown(\"2. Click on the **bottom-right** corner of the ROI.\")\n",
        "\n",
        "    # Create a copy of the original image to draw the rectangle\n",
        "    img_copy = image.copy()\n",
        "\n",
        "    # Create a streamlit canvas to handle mouse clicks\n",
        "    canvas = st.image(img_copy, use_column_width=True, clamp=True, channels=\"BGR\")\n",
        "\n",
        "    # Initialize variables to store the selected coordinates\n",
        "    top_left = None\n",
        "    bottom_right = None\n",
        "\n",
        "    def mouse_callback(event, x, y, flags, param):\n",
        "        nonlocal top_left, bottom_right\n",
        "\n",
        "        if event == cv2.EVENT_LBUTTONDOWN:\n",
        "            if top_left is None:\n",
        "                top_left = (x, y)\n",
        "            else:\n",
        "                bottom_right = (x, y)\n",
        "\n",
        "                # Draw a rectangle on the image copy to show the selected ROI\n",
        "                cv2.rectangle(img_copy, top_left, bottom_right, (0, 255, 0), 2)\n",
        "\n",
        "                # Update the streamlit canvas with the image copy\n",
        "                canvas.image(img_copy, channels=\"BGR\")\n",
        "\n",
        "    # Set up the mouse callback function\n",
        "    cv2.namedWindow(\"Select ROI\")\n",
        "    cv2.setMouseCallback(\"Select ROI\", mouse_callback)\n",
        "\n",
        "    # Keep the Streamlit app running until the user selects the ROI\n",
        "    while bottom_right is None:\n",
        "        st.experimental_rerun()\n",
        "\n",
        "    # Close the OpenCV window\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    return top_left, bottom_right\n",
        "\n",
        "\n",
        "# Main Streamlit app\n",
        "def main():\n",
        "    st.title(\"Image ROI Selection\")\n",
        "\n",
        "    st.header(\"Upload an Image\")\n",
        "    st.write(\"Please upload an image file (PNG, JPG, JPEG) to select the region of interest (ROI).\")\n",
        "\n",
        "    # File upload\n",
        "    uploaded_file = st.file_uploader(\"Choose an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the uploaded image\n",
        "        image = np.array(Image.open(uploaded_file))\n",
        "\n",
        "        # Display the original image\n",
        "        st.subheader(\"Original Image\")\n",
        "        st.image(image, use_column_width=True, channels=\"BGR\")\n",
        "\n",
        "        # Select the region of interest\n",
        "        st.header(\"Select ROI\")\n",
        "        st.write(\"Please follow the instructions to select the extreme coordinates of the ROI.\")\n",
        "\n",
        "        top_left, bottom_right = select_roi(image)\n",
        "\n",
        "        # Display the selected coordinates\n",
        "        st.header(\"Selected Coordinates\")\n",
        "        st.write(\"Top Left:\", top_left)\n",
        "        st.write(\"Bottom Right:\", bottom_right)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-3CeqpYxt2sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppU3gcrdt3x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "    st.title(\"Corner Coordinate Logger\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Display the uploaded image\n",
        "        st.image(uploaded_image, use_column_width=True)\n",
        "\n",
        "        # Get the corner coordinates\n",
        "        coordinates = []\n",
        "        click_count = 0\n",
        "\n",
        "        # Mouse click event handler\n",
        "        def get_click_coordinates(event):\n",
        "            nonlocal click_count\n",
        "            click_count += 1\n",
        "            coordinates.append((event.x, event.y))\n",
        "\n",
        "            if click_count >= 2:\n",
        "                # Display the coordinates\n",
        "                st.write(f\"Top-Left Corner: {coordinates[0]}\")\n",
        "                st.write(f\"Bottom-Right Corner: {coordinates[1]}\")\n",
        "\n",
        "        # Register the callback for mouse click events\n",
        "        st_canvas = st.image([0], use_column_width=True, width=uploaded_image.width, clamp=True)\n",
        "        st_canvas._image_data = uploaded_image\n",
        "        st_canvas._add_bokeh_mouse_callbacks(\"mousemove\", get_click_coordinates)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "lhOx17u5YLJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "def main():\n",
        "    st.title(\"Corner Coordinate Logger\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Display the uploaded image\n",
        "        pil_image = Image.open(uploaded_image)\n",
        "        st.image(pil_image, use_column_width=True)\n",
        "\n",
        "        # Get the corner coordinates\n",
        "        coordinates = []\n",
        "        click_count = 0\n",
        "\n",
        "        # Mouse click event handler\n",
        "        def get_click_coordinates(event):\n",
        "            nonlocal click_count\n",
        "            click_count += 1\n",
        "            coordinates.append((event.x, event.y))\n",
        "\n",
        "            if click_count >= 2:\n",
        "                # Display the coordinates\n",
        "                st.write(f\"Top-Left Corner: {coordinates[0]}\")\n",
        "                st.write(f\"Bottom-Right Corner: {coordinates[1]}\")\n",
        "\n",
        "        # Register the callback for mouse click events\n",
        "        st_canvas = st.image([0], use_column_width=True, width=pil_image.width, clamp=True)\n",
        "        st\n",
        "        _canvas._image_data = pil_image\n",
        "        st_canvas._add_bokeh_mouse_callbacks(\"mousemove\", get_click_coordinates)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "q_kn1dXwY_ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from streamlit_cropper import st_cropper\n",
        "from PIL import Image\n",
        "\n",
        "def main():\n",
        "    st.title(\"Corner Coordinate Logger\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Display the uploaded image\n",
        "        pil_image = Image.open(uploaded_image)\n",
        "        st.image(pil_image, use_column_width=True)\n",
        "\n",
        "        # Cropper component to select corners\n",
        "        cropped_image = st_cropper(pil_image)\n",
        "\n",
        "        if cropped_image is not None:\n",
        "            # Get the coordinates of the cropped image\n",
        "            top_left = (cropped_image[0][0], cropped_image[0][1])\n",
        "            bottom_right = (cropped_image[1][0], cropped_image[1][1])\n",
        "\n",
        "            # Display the coordinates\n",
        "            st.write(f\"Top-Left Corner: {top_left}\")\n",
        "            st.write(f\"Bottom-Right Corner: {bottom_right}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "t0LoL-Spbmd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "def process_image(image_data):\n",
        "    # Decode the base64 encoded image data\n",
        "    nparr = np.frombuffer(base64.b64decode(image_data), np.uint8)\n",
        "\n",
        "    # Decode the numpy array to an image\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image (e.g., resize, normalize, etc.)\n",
        "    # ...\n",
        "\n",
        "    return img\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1_data = request.form['image1']\n",
        "    image2_data = request.form['image2']\n",
        "\n",
        "    # Process the images\n",
        "    processed_image1 = process_image(image1_data)\n",
        "    processed_image2 = process_image(image2_data)\n",
        "\n",
        "    # Perform prediction using the loaded model and the processed images\n",
        "    prediction = model.predict([processed_image1, processed_image2])\n",
        "\n",
        "    # Create a dataframe of the predicted values\n",
        "    df = pd.DataFrame(prediction, columns=['Predicted Values'])\n",
        "\n",
        "    # Return the dataframe as JSON response\n",
        "    return df.to_json()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "import pandas as pd\n",
        "import base64\n",
        "import io\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Save the uploaded images\n",
        "    image_path1 = 'uploaded_image1.jpg'\n",
        "    image_path2 = 'uploaded_image2.jpg'\n",
        "    with open(image_path1, 'wb') as f1, open(image_path2, 'wb') as f2:\n",
        "        f1.write(uploaded_image1.getvalue())\n",
        "        f2.write(uploaded_image2.getvalue())\n",
        "\n",
        "    # Read the saved images as bytes\n",
        "    with open(image_path1, 'rb') as f1, open(image_path2, 'rb') as f2:\n",
        "        image_bytes1 = f1.read()\n",
        "        image_bytes2 = f2.read()\n",
        "\n",
        "    # Convert the image bytes to base64 encoded strings\n",
        "    image_data1 = base64.b64encode(image_bytes1).decode('utf-8')\n",
        "    image_data2 = base64.b64encode(image_bytes2).decode('utf-8')\n",
        "\n",
        "    # Send the base64 encoded image data to the API\n",
        "    data = {'image1': image_data1, 'image2': image_data2}\n",
        "    response = requests.post(API_URL, data=data)\n",
        "\n",
        "    # Convert the JSON response to a dataframe\n",
        "    df = pd.read_json(response.content)\n",
        "\n",
        "    # Display the dataframe\n",
        "    st.write('Predicted Values:')\n",
        "    st.dataframe(df)\n"
      ],
      "metadata": {
        "id": "HppPm8Zy1nGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "def process_image(image_data):\n",
        "    # Decode the base64 encoded image data\n",
        "    nparr = np.frombuffer(base64.b64decode(image_data), np.uint8)\n",
        "\n",
        "    # Decode the numpy array to an image\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image (e.g., resize, normalize, etc.)\n",
        "    # ...\n",
        "\n",
        "    return img\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1_data = request.form['image1']\n",
        "    image2_data = request.form['image2']\n",
        "\n",
        "    # Process the images\n",
        "    processed_image1 = process_image(image1_data)\n",
        "    processed_image2 = process_image(image2_data)\n",
        "\n",
        "    # Perform prediction using the loaded model and the processed images\n",
        "    prediction = model.predict([processed_image1, processed_image2])\n",
        "\n",
        "    # Create a dataframe of the predicted values\n",
        "    df = pd.DataFrame(prediction, columns=['Predicted Values'])\n",
        "\n",
        "    # Return the dataframe as JSON response\n",
        "    return df.to_json()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "import pandas as pd\n",
        "import base64\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Read the image files as bytes\n",
        "    image_bytes1 = uploaded_image1.read()\n",
        "    image_bytes2 = uploaded_image2.read()\n",
        "\n",
        "    # Convert the image bytes to base64 encoded strings\n",
        "    image_data1 = base64.b64encode(image_bytes1).decode('utf-8')\n",
        "    image_data2 = base64.b64encode(image_bytes2).decode('utf-8')\n",
        "\n",
        "    # Send the base64 encoded image data to the API\n",
        "    data = {'image1': image_data1, 'image2': image_data2}\n",
        "    response = requests.post(API_URL, data=data)\n",
        "\n",
        "    # Convert the JSON response to a dataframe\n",
        "    df = pd.read_json(response.content)\n",
        "\n",
        "    # Display the dataframe\n",
        "    st.write('Predicted Values:')\n",
        "    st.dataframe(df)\n"
      ],
      "metadata": {
        "id": "XYIKqYUvAeca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gm6GmPi61n4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (API)\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained ML model\n",
        "model = joblib.load('your_model.pkl')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded images from the request\n",
        "    image1 = request.files['image1']\n",
        "    image2 = request.files['image2']\n",
        "\n",
        "    # Save the uploaded images\n",
        "    image1_path = 'uploaded_image1.jpg'\n",
        "    image2_path = 'uploaded_image2.jpg'\n",
        "    image1.save(image1_path)\n",
        "    image2.save(image2_path)\n",
        "\n",
        "    # Perform prediction using the loaded model and the image paths\n",
        "    prediction = model.predict([image1_path, image2_path])\n",
        "\n",
        "    # Prepare the response\n",
        "    response = {\n",
        "        'prediction': prediction.tolist()\n",
        "    }\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "# streamlit_app.py (Streamlit)\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "# Define the API URL\n",
        "API_URL = 'http://localhost:5000/predict'\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ML Model API Demo')\n",
        "\n",
        "# Get user input\n",
        "uploaded_image1 = st.file_uploader('Upload Image 1', type=['jpg', 'jpeg', 'png'])\n",
        "uploaded_image2 = st.file_uploader('Upload Image 2', type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "# Process user input\n",
        "if uploaded_image1 and uploaded_image2:\n",
        "    # Send the uploaded images to the API\n",
        "    files = {'image1': uploaded_image1, 'image2': uploaded_image2}\n",
        "    response = requests.post(API_URL, files=files)\n",
        "\n",
        "    # Extract the prediction from the response\n",
        "    prediction = response.json()['prediction']\n",
        "\n",
        "    # Display the prediction\n",
        "    st.write('Prediction:', prediction)\n"
      ],
      "metadata": {
        "id": "WkNkDTFf8U4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MRW-Code/cmac_particle_flow.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irftjGuQ6odc",
        "outputId": "097102f2-7e58-42e5-85d0-9050b726084e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cmac_particle_flow' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cohesive='/content/cmac_particle_flow/images/Cohesive'\n",
        "easyflow='/content/cmac_particle_flow/images/Easyflowing'\n",
        "freeflow='/content/cmac_particle_flow/images/Freeflowing'"
      ],
      "metadata": {
        "id": "07RCuClT6xjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths=[]\n",
        "labels=[]\n",
        "import os\n",
        "\n",
        "for i in os.listdir(cohesive):\n",
        "  image_paths.append(os.path.join(cohesive,i))\n",
        "  labels.append(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "0JUbfmgK64LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(easyflow):\n",
        "  image_paths.append(os.path.join(easyflow,i))\n",
        "  labels.append(1)"
      ],
      "metadata": {
        "id": "h5VoNi7_64V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(freeflow):\n",
        "  image_paths.append(os.path.join(freeflow,i))\n",
        "  labels.append(2)"
      ],
      "metadata": {
        "id": "3JCDVL_r64Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "image_data = {'path': image_paths, 'label': labels}\n",
        "df = pd.DataFrame(data=image_data)"
      ],
      "metadata": {
        "id": "kyZEJv1W64cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_jJj5HC64fs",
        "outputId": "06beda66-fe29-400c-ad8c-0121429abdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 path  label\n",
            "0   /content/cmac_particle_flow/images/Cohesive/Az...      0\n",
            "1   /content/cmac_particle_flow/images/Cohesive/Pa...      0\n",
            "2   /content/cmac_particle_flow/images/Cohesive/1-...      0\n",
            "3   /content/cmac_particle_flow/images/Cohesive/Mo...      0\n",
            "4   /content/cmac_particle_flow/images/Cohesive/Li...      0\n",
            "..                                                ...    ...\n",
            "92  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "93  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "94  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "95  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "96  /content/cmac_particle_flow/images/Freeflowing...      2\n",
            "\n",
            "[97 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "UG63cQ4a7CDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label']=df['label'].map({0:'Cohesive',1:'Easyflow',2:'Freeflow'})"
      ],
      "metadata": {
        "id": "NG_Om_H77Gfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ],
      "metadata": {
        "id": "tccwMNYc7TPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an instance of the ImageDataGenerator for preprocessing the images\n",
        "data_gen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "# Create a train data generator from the train dataframe\n",
        "train_data_gen = data_gen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    x_col=\"path\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(384, 384),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Create a validation data generator from the validation dataframe\n",
        "val_data_gen = data_gen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    x_col=\"path\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(384, 384),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained Vision Transformer model\n",
        "vision_transformer = tf.keras.applications.vgg16.VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(384, 384, 3)\n",
        ")\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in vision_transformer.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add the classification head on top of the pre-trained layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        vision_transformer,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=43,\n",
        "    validation_data=val_data_gen,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "y2UlhaAS7I6o",
        "outputId": "88a2b85a-6df5-4100-c7d8-dc6434a4896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b34b53433b6b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create an instance of the ImageDataGenerator for preprocessing the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m data_gen = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "id": "1fazDpFVTulD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "Wc4ywEk0Scvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.models.load_model('path/to/your/model.h5')\n",
        "\n",
        "# Load and preprocess the input image\n",
        "image_path = '/content/cmac_particle_flow/images/Cohesive/Span 60_19mm.jpg'\n",
        "input_size = (384, 384)  # Adjust this to match the input size of your model\n",
        "\n",
        "# Load the image\n",
        "image = load_img(image_path, target_size=input_size)\n",
        "image = img_to_array(image)\n",
        "# image /= 255.0  # Apply the scaling factor\n",
        "\n",
        "# Expand dimensions to create a batch of size 1\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Preprocess the input image\n",
        "image = preprocess_input(image)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Decode the predictions\n",
        "# (Adjust this part based on the output format of your model)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "probability = np.max(predictions, axis=1)\n",
        "\n",
        "# Print the predicted class and probability\n",
        "print(f'Predicted Class: {predicted_class[0]}')\n",
        "print(f'Probability: {probability[0] * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "8C53-JiG7Olw",
        "outputId": "c067cbf1-dc7a-48bf-f14f-1e3c1c122159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8bf3dd8ed4a2>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Expand dimensions to create a batch of size 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Preprocess the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install timm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlEES9XubDdP",
        "outputId": "2c87dd56-f90e-44aa-ff2d-2048823ce8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm"
      ],
      "metadata": {
        "id": "khECZTTXZybS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHUeoSTSjUf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}