{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarunNagdeve/Cats-Vs-Dogs/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVOtyjwQmiYv",
        "outputId": "00c28381-3b0f-4e12-f402-94b3eaabd832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting django\n",
            "  Downloading Django-4.2.4-py3-none-any.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asgiref<4,>=3.6.0 (from django)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.6.0->django) (4.7.1)\n",
            "Installing collected packages: asgiref, django\n",
            "Successfully installed asgiref-3.7.2 django-4.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install django"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load your data frames (adjust this part)\n",
        "data_frames = [df1, df2, df3]  # List of your data frames\n",
        "\n",
        "# Prepare a list to store all embeddings and metadata\n",
        "all_embeddings = []\n",
        "metadata = []  # Store metadata like document index and text index\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Iterate over each data frame\n",
        "for doc_index, df in enumerate(data_frames):\n",
        "    # Assuming your data frame has a column named 'text' containing text data\n",
        "    text_data = df['text'].tolist()\n",
        "\n",
        "    # Convert text data to TF-IDF embeddings\n",
        "    tfidf_matrix = vectorizer.fit_transform(text_data)\n",
        "\n",
        "    # Convert sparse matrix to dense array\n",
        "    embeddings = tfidf_matrix.toarray()\n",
        "\n",
        "    # Store embeddings and metadata\n",
        "    all_embeddings.extend(embeddings)\n",
        "    for text_index in range(len(embeddings)):\n",
        "        metadata.append({'doc_index': doc_index, 'text_index': text_index})\n",
        "\n",
        "# Convert the list of metadata into a numpy array\n",
        "metadata_array = np.array(metadata)\n",
        "\n",
        "# Normalize the embeddings\n",
        "all_embeddings /= (np.linalg.norm(all_embeddings, axis=1, keepdims=True) + 1e-6)\n",
        "\n",
        "# Create a FAISS index\n",
        "d = len(all_embeddings[0])  # Dimension of embeddings\n",
        "index = faiss.IndexFlatIP(d)  # Use Inner Product (IP) similarity measure\n",
        "\n",
        "# Train the index on your data\n",
        "index.add(all_embeddings)\n",
        "\n",
        "# Example search (adjust the query_embedding)\n",
        "query_embedding = ...  # Your query embedding\n",
        "k = 5  # Number of nearest neighbors to retrieve\n",
        "D, I = index.search(query_embedding, k)\n",
        "\n",
        "# Now you can use the metadata_array to map back to specific text entries\n",
        "for distances, indices in zip(D, I):\n",
        "    for distance, index in zip(distances, indices):\n",
        "        text_metadata = metadata_array[index]\n",
        "        doc_index = text_metadata['doc_index']\n",
        "        text_index = text_metadata['text_index']\n",
        "        print(f\"Document {doc_index}, Text Entry {text_index}, Distance: {distance}\")\n"
      ],
      "metadata": {
        "id": "UcrfBfRoGPq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rest_framework.views import APIView\n",
        "from rest_framework.response import Response\n",
        "from rest_framework import status\n",
        "from .models import SentimentAnalysisResult\n",
        "from .serializers import SentimentAnalysisResultSerializer\n",
        "import your_ml_library  # Import your ML library and model here\n",
        "\n",
        "class SentimentAnalysisAPI(APIView):\n",
        "    def post(self, request, format=None):\n",
        "        input_text = request.data.get('input_text', '')\n",
        "\n",
        "        # Perform sentiment analysis using your ML model\n",
        "        sentiment_output = your_ml_library.perform_sentiment_analysis(input_text)\n",
        "\n",
        "        # Save the result to the database\n",
        "        sentiment_result = SentimentAnalysisResult(input_text=input_text, sentiment_output=sentiment_output)\n",
        "        sentiment_result.save()\n",
        "\n",
        "        serializer = SentimentAnalysisResultSerializer(sentiment_result)\n",
        "        return Response(serializer.data, status=status.HTTP_201_CREATED)\n"
      ],
      "metadata": {
        "id": "QKjsgE1f8067"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Example text\n",
        "example_text = \"\"\"\n",
        "Some text here.\n",
        "6.0 PROCEDURE\n",
        "This is the procedure section.\n",
        "It can have multiple lines.\n",
        "7.0 LIST\n",
        "This is the list section.\n",
        "End of the text.\n",
        "\"\"\"\n",
        "\n",
        "# Define the regex pattern\n",
        "pattern = re.compile(r'6\\.0 PROCEDURE(.*?)7\\.0 LIST', re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "# Find the matched text\n",
        "match = re.search(pattern, example_text)\n",
        "\n",
        "# Extract the matched content\n",
        "if match:\n",
        "    extracted_text = match.group(1).strip()\n",
        "    print(extracted_text)\n"
      ],
      "metadata": {
        "id": "IxxMKxhNf9ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import milvus\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Connect to the Milvus server\n",
        "milvus_client = milvus.Milvus(host='localhost', port='19530')\n",
        "\n",
        "# Create a Milvus collection for each document\n",
        "document_collection_names = ['document_1', 'document_2', 'document_3']  # Adjust as needed\n",
        "\n",
        "# Iterate over each document\n",
        "for doc_index, collection_name in enumerate(document_collection_names):\n",
        "    # Load section indexes and text entries for the current document (adjust as needed)\n",
        "    section_indexes = [1, 2, 3, ...]  # Load your section indexes\n",
        "    text_entries = [\"text entry 1\", \"text entry 2\", \"text entry 3\", ...]  # Load your text entries\n",
        "\n",
        "    # Convert text to embeddings using TF-IDF\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(text_entries)\n",
        "    embeddings = X.toarray()\n",
        "\n",
        "    # Create a collection for the current document\n",
        "    milvus_client.create_collection({\n",
        "        'collection_name': collection_name,\n",
        "        'dimension': len(embeddings[0]) + 2,  # Embeddings + 2 for text and section indexes\n",
        "        'index_file_size': 1024,\n",
        "        'metric_type': milvus.MetricType.IP  # Choose appropriate metric type\n",
        "    })\n",
        "\n",
        "    # Create a list of dictionaries containing embeddings, text, and section indexes\n",
        "    entities = [{'embedding': emb.tolist(), 'text': text, 'section_index': section}\n",
        "                for emb, text, section in zip(embeddings, text_entries, section_indexes)]\n",
        "\n",
        "    # Insert embeddings, text, and section indexes into the collection\n",
        "    ids = milvus_client.insert(collection_name=collection_name, records=entities)\n",
        "\n",
        "# Close the Milvus connection\n",
        "milvus_client.close()\n"
      ],
      "metadata": {
        "id": "JmlqfPwYhnsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWsBTOjrmuB_"
      },
      "outputs": [],
      "source": [
        "!django-admin startproject MyAPI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9St51hQonM6e"
      },
      "outputs": [],
      "source": [
        "! cd MyAPI/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DIEfYfqBpv9w",
        "outputId": "7c9cf0db-1b34-4645-dc47-af9f0aed90f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://ui1ofxe6uh-496ff2e9c6d22116-8000-colab.googleusercontent.com/\n"
          ]
        }
      ],
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(8000)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yOcRUzenZwW"
      },
      "outputs": [],
      "source": [
        "ALLOWED_HOSTS = ['colab.research.google.com']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGTmnjpFp574",
        "outputId": "2f447168-5ed6-4b50-a76f-d9134040bbab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Watching for file changes with StatReloader\n",
            "Performing system checks...\n",
            "\n",
            "System check identified no issues (0 silenced).\n",
            "\u001b[31m\n",
            "You have 18 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions.\u001b[0m\n",
            "\u001b[31mRun 'python manage.py migrate' to apply them.\u001b[0m\n",
            "August 26, 2023 - 07:04:07\n",
            "Django version 4.2.4, using settings 'MyAPI.settings'\n",
            "Starting development server at http://127.0.0.1:8000/\n",
            "Quit the server with CONTROL-C.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/MyAPI/manage.py runserver 8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4GIf0TEp9y3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO92qweDgdJ5dMYdP7/NJs+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}