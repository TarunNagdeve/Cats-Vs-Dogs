{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP2t5GJuzjXmp4bYhFkFOZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarunNagdeve/Cats-Vs-Dogs/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TetghydNSwp0"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# Create a Streamlit app\n",
        "st.title(\"Zip File Upload and Save Example\")\n",
        "\n",
        "# Use st.file_uploader() to let the user upload a zip file\n",
        "zip_file = st.file_uploader(\"Upload a zip file\", type=[\"zip\"])\n",
        "\n",
        "# Check if a zip file was uploaded\n",
        "if zip_file:\n",
        "    st.write(\"You uploaded a zip file:\", zip_file)\n",
        "\n",
        "    # You can choose a destination directory where you want to save the extracted contents\n",
        "    destination_directory = \"path/to/your/destination\"\n",
        "\n",
        "    # Check if the destination directory exists, and create it if it doesn't\n",
        "    if not st.file_uploader:\n",
        "        os.makedirs(destination_directory)\n",
        "\n",
        "    # Extract the zip file\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination_directory)\n",
        "\n",
        "    st.write(\"Zip file extracted and saved to the destination:\", destination_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_store.faiss import FAISSDocumentStore\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from haystack.schema import Document\n",
        "\n",
        "# Initialize the FAISS document store\n",
        "document_store = FAISSDocumentStore(sql_url=\"sqlite:///my_faiss_store.db\", index=\"hnsw_flat\")\n",
        "\n",
        "# Initialize a SentenceTransformer model\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "# Generate embeddings for your data and store them in FAISS\n",
        "for entry in data_to_index:\n",
        "    content = entry[\"data\"]  # Extract the text content\n",
        "    embedding = model.encode(content)  # Generate the embedding\n",
        "\n",
        "    # Create a FAISSDocument with 'content' and 'meta' fields\n",
        "    document = Document(content=content, meta={\"docs\": entry[\"docs\"], \"indexes\": entry[\"indexes\"]})\n",
        "\n",
        "    # Store the document with the embedding in FAISS\n",
        "    document_store.write_documents([document], index=\"hnsw_flat\", update_existing=True)\n"
      ],
      "metadata": {
        "id": "R4QZPaqXxF28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_store.faiss import FAISSDocumentStore\n",
        "\n",
        "# Initialize the FAISS document store\n",
        "document_store = FAISSDocumentStore(sql_url=\"sqlite:///my_faiss_store.db\", index=\"hnsw_flat\")\n",
        "\n",
        "# Your dataset\n",
        "data_to_index = [\n",
        "    {\"data\": \"Text from document 1, section A\", \"docs\": \"document1\", \"indexes\": \"A\"},\n",
        "    {\"data\": \"Text from document 1, section B\", \"docs\": \"document1\", \"indexes\": \"B\"},\n",
        "    {\"data\": \"Text from document 2, section A\", \"docs\": \"document2\", \"indexes\": \"A\"},\n",
        "    # Add more data entries as needed\n",
        "]\n",
        "\n",
        "# Store the data in FAISS\n",
        "for entry in data_to_index:\n",
        "    document_store.write_documents([{\"text\": entry[\"data\"], \"meta\": {\"docs\": entry[\"docs\"], \"indexes\": entry[\"indexes\"]}],\n",
        "                                   update_existing=True)\n"
      ],
      "metadata": {
        "id": "pf1x5Rr2yjb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}